\renewcommand{\thefootnote}{\alph{footnote}} % Use letters for footnotes

\section{Methods}

All modelling and analysis was performed using Python in Jupyter Notebooks \cite{kluyver_jupyter_2016}, with general analysis and plotting performed using NumPy \cite{harris_array_2020}, Pandas \cite{mckinney-proc-scipy-2010}, Scikit-Learn  \cite{pedregosa_scikit-learn_2011}, and Matplotlib \cite{hunter_matplotlib_2007}. 

Further details of methods may also be found in the appendix. 

All code, with detailed results, used is available online as a Jupyter book at \url{https://samuel-book.github.io/samuel_shap_paper_1/} and available on GitHub \cite{samuel_paper_1_github}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Data}

Data were retrieved for 246,676 emergency stroke admissions to acute stroke teams in England and Wales for the three calendar years 2016 - 2018, obtained from the Sentinel Stroke National Audit Programme\footnote{https://www.strokeaudit.org/} (SSNAP). Data fields were provided for the hyper-acute phase of the stroke pathway, up to and including our target feature: \emph{receive thrombolysis} (full details of the data fields obtained are provided in the appendix). Of these patients, 88,928 arrived within 4 hours of known (precise or estimated) stroke onset, and were used in this modelling study (as they represent the patients that had time left to receive thrombolysis). The data included 132 acute stroke hospitals (these were all units admitting an average of 100 patients per year, and delivering thrombolysis to at least 10 patients over 3 years). For modelling purposes, the categorical feature \emph{Stroke team} in the SSNAP dataset was represented as 132 one-hot encoded features (a separate feature for each hospital). One-hot encoding is a process which converts a categorical feature to a numerical form. There are 60 original features used from the SSNAP dataset (before one-hot encoding categorical features).

 SSNAP has near-complete coverage of all acute stroke admissions in the UK (outside Scotland). All hospitals admitting acute stroke participate in the audit, and year-on-year comparison with Hospital Episode Statistics\footnote{https://digital.nhs.uk/data-and-information/data-tools-and-services/data-services/hospital-episode-statistics} confirms estimated case ascertainment of 95\% of coded cases of acute stroke.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Machine learning models (to predict thrombolysis use)}
We used an \emph{eXtreme Gradient Boosting model \cite{chen_xgboost_2016}} (`XGBoost') to predict the probability of use of thrombolysis for each patient from their other feature values. We chose XGBoost for its efficiency, and because we working with a system with known non-linear relationships and potential feature interactions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Feature selection}
Before applying SHAP, we aimed to enhance the understandability and explainability of our models through restricting the features (patient level data fields) included in the model. 

Features were selected one at a time from the 60 original features in the SSNAP dataset by forward-feature selection \cite{ferri_comparative_1994} (identifying one feature at a time that led to the greatest improvement in accuracy). Model accuracy was measured by Receiver Operating Characteristic (ROC) Area Under Curve (AUC), using 5-fold cross-validation. We repeated this process to identify the top 25 features, and used these results to identify the number of features to include in our machine learning models (based on the observed diminishing returns).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Model accuracy}
Model accuracy, ROC AUC, sensitivity and specificity were measured using stratified 5-fold cross validation. The appendix contains further model accuracy analysis.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{The machine learning models}

For the different analysis included in this paper, we trained three XGBoost models:
\begin{enumerate}
    \item {\emph{K-fold model}}
    
    Description: Train/test five models using all 88,928 patients in a 5-fold cross-validation.
    
    Purpose: To robustly test the accuracy of the model, and to test reproducibility of SHAP values across the five k-fold models.
    
    \item {\emph{All data model}}
    
    Description: Train a single model using all 88,928 patients.
    
    Purpose: Having understood the model accuracy (from the \emph{k-fold model}), we used all the data to create a single model to understand and explain predicitons.
    
    \item {\emph{10k holdout model}}

    Description: Select 10k patients (stratified by hospital and thrombolysis use) to keep in a hold-back dataset, and train a single model using the remaining 78,928 patients. 
    
    Purpose: By passing all of the 10k patients (that were held back from the training process) through the fitted model, whilst setting the hospital attended feature to each hospital in turn, we predicted the thrombolysis rate for each hospital if all hospitals saw the same patients, revealing the variation in thrombolysis that is caused by the hospital, rather than by between-hospital variation in patient populations.
\end{enumerate}

For all models, a single model was fitted for all hospitals, with hospital attended being a feature (represented as a one-hot encoded feature).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{SHapley Additive exPlanation (SHAP) values}

We sought to make our models explainable using SHAP values (calculated using the SHAP library \cite{lundberg_unified_2017}). SHAP provides a measure of the contribution of each feature value to the final predicted probability of receiving thrombolysis for that individual. The SHAP values for each feature are comprised of the feature’s main effect (the effect of that feature in isolation) and all of the pairwise interaction effects with each of the other features (a value per feature pairing). SHAP values provide the influence of each feature as the change in log-odds of receiving thrombolysis. SHAP values expressed as log-odds are additive, i.e. the final log-odds of receiving thrombolysis is the sum of the base model prediction (the log-odds of receiving thrombolysis before feature influences are considered), and the SHAP values for each feature (comprised of the feature's main effect and all of the pairwise interaction effects with each of the other features). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The relationship between feature values and the odds of receiving thrombolysis}

For each feature, we examined the relationship between feature values and their corresponding SHAP values (we used values from the \emph{all data} model).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{How much of the between-hospital thrombolysis use can be explained by the identity of the hospital attended?}

For each hospital we compared the mean SHAP main effect value for the hospital attended (using values from the \emph{all data} model) with the hospitals observed thrombolysis use. Each hospital has their own patient population.

To reveal the variation in thrombolysis rate due to hospital, rather than patient mix, we also compared the mean hospital attended SHAP main effect value for the identical 10k patient cohort attending each hospital, with the hospitals' predicted thrombolysis use for this 10k patient cohort (we used values from the \emph{10k holdout} model).

By using the SHAP main effect (instead of the full SHAP value) it removes all interactions with the other features, which prevents the possible leakage of patient information into the hospital attended value.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{How much of the between-hospital thrombolysis use can be explained by the differences in the hospital identity and processes, and the differences in the patient populations?}

%Hospital attended SHAP values are comprised of the attended hospital's main effect and the sum of its interactions with all other features. This includes interactions with the features that describe the patient, which could allow for possible leakage of patient information into the hospital attended SHAP value. We may further isolate the effect of the hospital or patients by including only the interactions with other related features.

The 10 features in the model can be classified into two subsets: 1) `patient descriptive features' (features that describe the patients characteristics), and 2) `hospital descriptive features' (features that describe the hospital’s identity or process). To analyse the influence that each subset of features has on the thromoblysis rate, we calculated the `subset SHAP value' for each feature, which only includes the components of its SHAP value that contain effects from the features in the same subset. This is expressed as the sum of the main effect and the interaction effects with the other features in the same subset. For each subset of features (hospital, or patient) we fitted a multiple regression to predict the hospitals observed thrombolysis rate from the mean subset SHAP value of each feature, for patients attending each hospital (using values from the \emph{all data} model). We also fitted a multiple regression using the subset SHAP values for all 10 features (both hospital and patient descriptive features). For this analysis, we only included the single one-hot encoded feature for the attended hospital. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Variation in hospital thrombolysis use for patient subgroups}

Informed by the SHAP values, we analysed the observed and predicted use of thrombolysis in eleven subgroups of patients: one subgroup for `ideally' thrombolysable patients, nine `sub-optimal' thrombolysable patient subgroups (one subgroup per feature), and one subgroup with two sub-optimal features. We based the ideally thrombolysable definition on observing the relationships between feature values and thrombolysis use. The `sub-optimal' patient subgroups were selected from all patients, apart from using a cut-off of one feature for each group. The eleven patient subgroups are defined as:

\begin{enumerate}
  \item An \emph{`ideally'} thrombolysable patient:
  \begin{itemize}
    \setlength\itemsep{-2mm}
    \item Mid-level stroke severity (NIHSS in range 10-25)
    \item Short arrival-to-scan time (less than 30 minutes)
    \item Stroke caused by infarction
    \item Precise stroke onset time known
    \item No pre-stroke disability (mRS 0)
    \item Not taking atrial fibrillation anticoagulants
    \item Short onset-to-arrival time (less than 90 minutes)
    \item Younger than 80 years old
    \item Onset not during sleep
  \end{itemize}
  \item Patients with a mild stroke severity (NIHSS less than 5)
  \item Patients where stroke onset time known imprecisely
  \item Patients with pre-stroke disability (mRS greater than 2)
  \item Patients with a haemorrhagic stroke
  \item Patients with 60-90 minutes arrival-to-scan time
  \item Patients with use of AF anticoagulants
  \item Patients with 150-180 minutes onset-to-arrival time
  \item Patients with onset during sleep
  \item Patients aged over 80 years old
  \item Patients with a mild stroke severity (NIHSS less than 5) and with estimated stroke onset time
\end{enumerate}

The observed thrombolysis use at each hospital was taken from the SSNAP dataset, with data limited to the patients that matched the patient characteristics and attending each hospital (and so the patient population was different for each hospital).

In order to reveal the variation in thrombolysis that was due to hospital decision-making we predicted thrombolysis use for the same patient subgroups at each hospital by using the \emph{10k holdout} model.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
